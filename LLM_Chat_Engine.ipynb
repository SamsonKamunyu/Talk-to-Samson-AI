{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4efea-3f86-4cfd-84f5-c1b603e0858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96b877-1857-4f6c-b572-17ae5e033eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing working libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "#import as `from :class:`~langchain_openai import ChatOpenAI``\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd1efc-5514-4e93-bf11-5a503e27499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Prompts\\persona_prompt.txt\", encoding='utf-8') as f:\n",
    "    persona_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b54c80-525e-4cf2-9a0e-43630fd605f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the processed training dataset\n",
    "with open(r\"C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Raw Data\\Text Files-Processed\\combined-dataset.json\") as f:\n",
    "    samples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb6c04-92c1-4139-a8c4-d6f9b1ac7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chatbot\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4\")\n",
    "\n",
    "def get_response(user_input):\n",
    "    messages = [\n",
    "        SystemMessage(content=persona_prompt),\n",
    "        HumanMessage(content=user_input)\n",
    "    ]\n",
    "    response = llm(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d2d96-3dc3-4e87-90cd-2f94b54d8904",
   "metadata": {},
   "source": [
    "## BARK - Audio Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5133dc-600c-4d5a-8d8e-0a163e8eb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e135c8-35ad-429e-b547-c45715cb32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bark import SAMPLE_RATE, generate_audio\n",
    "# from scipy.io.wavfile import write\n",
    "\n",
    "# text_prompt = \"Hey, itâ€™s Samson. Chill, relax, sleep then get back on it ASAP!\"\n",
    "# audio_array = generate_audio(text_prompt)\n",
    "\n",
    "# write(\"samson_output.wav\", SAMPLE_RATE, audio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c1406-3896-4267-8378-293ef2a2f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79081da4-4d1c-4f4e-ad5a-bf6fe28816ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bark.generation import load_codec_model\n",
    "from encodec.utils import convert_audio\n",
    "from transformers import HubertModel, HubertTokenizer, HubertForSequenceClassification, HubertForCTC\n",
    "from hubert.hubert_manager import HuBERTManager\n",
    "from hubert.pre_kmeans_hubert import CustomHubert\n",
    "from hubert.customtokenizer import CustomTokenizer\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load and process your audio\n",
    "audio_filepath = r'C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Raw Data\\Audio Files-Processed\\short_audiomass-output.mp3'\n",
    "voice_name = \"cloned_myvoice\"\n",
    "output_path = r'C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Raw Data\\Audio Files-Processed' + voice_name + '.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb53f70-fe97-4891-a808-f395cdf47fdc",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc37cd-3e11-4612-a057-d180554947f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voice_bark.py\n",
    "from bark import generate_audio, SAMPLE_RATE\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "\n",
    "def speak_as_samson(text, output_path=\"output_samson.wav\"):\n",
    "    audio_array = generate_audio(text)\n",
    "    write(output_path, SAMPLE_RATE, audio_array)\n",
    "    os.system(f\"ffplay -nodisp -autoexit {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b31c3-2b42-4f80-ba8e-33bcef0f9b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
