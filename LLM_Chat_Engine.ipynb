{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e4efea-3f86-4cfd-84f5-c1b603e0858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca96b877-1857-4f6c-b572-17ae5e033eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing working libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "#import as `from :class:`~langchain_openai import ChatOpenAI``\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfcd1efc-5514-4e93-bf11-5a503e27499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Prompts\\persona_prompt.txt\", encoding='utf-8') as f:\n",
    "    persona_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b54c80-525e-4cf2-9a0e-43630fd605f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the processed training dataset\n",
    "with open(r\"C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Raw Data\\Text Files-Processed\\combined-dataset.json\") as f:\n",
    "    samples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdcb6c04-92c1-4139-a8c4-d6f9b1ac7ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25471\\AppData\\Local\\Temp\\ipykernel_1544\\2803882879.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4\")\n"
     ]
    }
   ],
   "source": [
    "# Create chatbot\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4\")\n",
    "\n",
    "def get_response(user_input):\n",
    "    messages = [\n",
    "        SystemMessage(content=persona_prompt),\n",
    "        HumanMessage(content=user_input)\n",
    "    ]\n",
    "    response = llm(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d2d96-3dc3-4e87-90cd-2f94b54d8904",
   "metadata": {},
   "source": [
    "## BARK - Audio Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a5133dc-600c-4d5a-8d8e-0a163e8eb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5e135c8-35ad-429e-b547-c45715cb32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bark import SAMPLE_RATE, generate_audio\n",
    "# from scipy.io.wavfile import write\n",
    "\n",
    "# text_prompt = \"Hey, itâ€™s Samson. Chill, relax, sleep then get back on it ASAP!\"\n",
    "# audio_array = generate_audio(text_prompt)\n",
    "\n",
    "# write(\"samson_output.wav\", SAMPLE_RATE, audio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c2c1406-3896-4267-8378-293ef2a2f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\25471\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\25471\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\25471\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\25471\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\25471\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\25471\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\25471\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\25471\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\25471\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\25471\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\25471\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79081da4-4d1c-4f4e-ad5a-bf6fe28816ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HubertTokenizer' from 'transformers' (C:\\Users\\25471\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_codec_model\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mencodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_audio\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HubertModel, HubertTokenizer, HubertForSequenceClassification, HubertForCTC\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhubert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhubert_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuBERTManager\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhubert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpre_kmeans_hubert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomHubert\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'HubertTokenizer' from 'transformers' (C:\\Users\\25471\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from bark.generation import load_codec_model\n",
    "from encodec.utils import convert_audio\n",
    "from transformers import HubertModel, HubertTokenizer, HubertForSequenceClassification, HubertForCTC\n",
    "from hubert.hubert_manager import HuBERTManager\n",
    "from hubert.pre_kmeans_hubert import CustomHubert\n",
    "from hubert.customtokenizer import CustomTokenizer\n",
    "import torchaudio\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load and process your audio\n",
    "audio_filepath = r'C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Raw Data\\Audio Files-Processed\\short_audiomass-output.mp3'\n",
    "voice_name = \"cloned_myvoice\"\n",
    "output_path = r'C:\\Users\\25471\\Documents\\Python\\Samson_AI\\Talk-to-Samson-AI\\Raw Data\\Audio Files-Processed' + voice_name + '.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c0436-791b-4a5a-aea3-991e86258b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
